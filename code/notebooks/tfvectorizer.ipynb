{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6559db19-fcf7-44ea-ac01-a0e4031a2fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from datasets import (\n",
    "    Dataset,\n",
    "    load_from_disk,\n",
    "    concatenate_datasets,\n",
    ")\n",
    "\n",
    "from preprocess import preprocess_retrieval, tokenizer_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36b829df-7208-4247-abe4-3c5d81f85529",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"xlm-roberta-large\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38318825-c34d-434a-902d-57ba30843a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/wikipedia_documents.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    wiki = json.load(f)\n",
    "\n",
    "contexts = list(dict.fromkeys([v[\"text\"] for v in wiki.values()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a982849-6ced-417f-add2-32e2498f50f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'이 문서는 나라 목록이며, 전 세계 206개 나라의 각 현황과 주권 승인 정보를 개요 형태로 나열하고 있다.\\n\\n이 목록은 명료화를 위해 두 부분으로 나뉘어 있다.\\n\\n# 첫 번째 부분은 바티칸 시국과 팔레스타인을 포함하여 유엔 등 국제 기구에 가입되어 국제적인 승인을 널리 받았다고 여기는 195개 나라를 나열하고 있다.\\n# 두 번째 부분은 일부 지역의 주권을 사실상 (데 팍토) 행사하고 있지만, 아직 국제적인 승인을 널리 받지 않았다고 여기는 11개 나라를 나열하고 있다.\\n\\n두 목록은 모두 가나다 순이다.\\n\\n일부 국가의 경우 국가로서의 자격에 논쟁의 여부가 있으며, 이 때문에 이러한 목록을 엮는 것은 매우 어렵고 논란이 생길 수 있는 과정이다. 이 목록을 구성하고 있는 국가를 선정하는 기준에 대한 정보는 \"포함 기준\" 단락을 통해 설명하였다. 나라에 대한 일반적인 정보는 \"국가\" 문서에서 설명하고 있다.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contexts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55fdbbbd-ce72-4f47-99ed-8b7db5fbf03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1aa5448-e19b-45c5-9128-a0fc2ae59875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "나는 <unk> <unk> <unk> 이다.\n",
      "[37231, 6, 3, 6, 3, 6, 3, 6, 5769, 5]\n",
      "['▁나는', '▁', '뷀뷁', '▁', '뙇', '▁', '뛓', '▁', '이다', '.']\n",
      "10 10\n"
     ]
    }
   ],
   "source": [
    "txt = \"나는 뷀뷁 뙇 뛓 이다.\"\n",
    "encoded = tokenizer(txt)['input_ids'][1:-1]\n",
    "tokenized = tokenizer.tokenize(txt)\n",
    "print(tokenizer.decode(encoded))\n",
    "print(encoded)\n",
    "print(tokenized)\n",
    "print(len(encoded), len(tokenized))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69487217-e738-4965-a35d-cbd4827def3c",
   "metadata": {},
   "source": [
    "띄어쓰기(_) : 6, UNK : 3 & UNK에 대해서 tokenize는 되지만 encoding은 안되는 듯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d270a5e7-2675-4469-ac1d-30bb327ae07b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "300c7dfa7f244101b1e6b22376c70cdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=56737.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f41265d3d7814e82aa44c157d5242de1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=56737.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1090 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "58894"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed = []\n",
    "tokens = []\n",
    "\n",
    "for context in tqdm(contexts):\n",
    "    preprocessed.append(preprocess_retrieval(context))\n",
    "    \n",
    "for context in tqdm(preprocessed):\n",
    "    tokens.extend(tokenizer.tokenize(context))\n",
    "    \n",
    "counter = Counter(tokens)\n",
    "len(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee22befb-7ca7-4d0d-8995-01187f3fec91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "collections.Counter"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea33f82a-8c9c-4685-909d-d2a2b48f385a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('▁', 1135789),\n",
       " ('의', 393949),\n",
       " ('을', 282722),\n",
       " ('에', 269607),\n",
       " ('이', 212962),\n",
       " ('은', 195973),\n",
       " ('는', 182049),\n",
       " ('년', 176928),\n",
       " ('를', 175570),\n",
       " ('로', 154598),\n",
       " ('가', 150453),\n",
       " ('에서', 138644),\n",
       " ('▁이', 118016),\n",
       " ('으로', 115491),\n",
       " ('한', 107940),\n",
       " ('고', 99520),\n",
       " ('과', 97610),\n",
       " ('인', 97240),\n",
       " ('도', 89708),\n",
       " ('와', 86126),\n",
       " ('월', 83608),\n",
       " ('리', 78023),\n",
       " ('지', 76937),\n",
       " ('일', 75681),\n",
       " ('사', 74154),\n",
       " ('스', 74053),\n",
       " ('▁수', 72838),\n",
       " ('기', 65315),\n",
       " ('다', 64811),\n",
       " ('▁있다', 64410),\n",
       " ('어', 60382),\n",
       " ('했다', 57025),\n",
       " ('시', 56950),\n",
       " ('르', 55938),\n",
       " ('하였다', 55020),\n",
       " ('▁그', 54385),\n",
       " ('자', 54093),\n",
       " ('하는', 53734),\n",
       " ('라', 52647),\n",
       " ('해', 51633),\n",
       " ('▁전', 51362),\n",
       " ('하고', 50673),\n",
       " ('이다', 47929),\n",
       " ('부', 47854),\n",
       " ('하여', 46230),\n",
       " ('군', 45556),\n",
       " ('▁1', 45034),\n",
       " ('▁가', 44516),\n",
       " ('▁사', 44447),\n",
       " ('대', 44442)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter.most_common(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "918aa2d1-7179-4559-aa15-4c9b94615ca4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22725190"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68eb74ae-b7de-4cd4-8949-6b492009f810",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def preprocess_retrieval(corpus):\n",
    "    corpus = corpus.replace(f\"\\n\", \"\")\n",
    "    corpus = re.sub(f\"[\\\"<>\\[\\].,?!\\(\\)\\:#\\|'\\=-]\", \" \", corpus)\n",
    "    corpus = ' '.join(corpus.split())\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1679f231-7d29-41e5-804b-be873e4d3ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁동', '부', '검', '은', '손', '타', '마', '린', '은', '▁18', '07', '년', '▁다른', '▁타', '마', '린', '과', '▁함께', '▁독일', '▁과학', '자', '▁요', '한', '▁호', '프', '만', '제', '크', '▁Johann', '▁Cent', 'uri', 'us', '▁Hoffman', 'nse', 'gg', '▁가', '▁타', '마', '린', '속', '의', '▁모', '식', '종', '으로', '▁기술', '했다', '▁나중에', '▁동', '부', '검', '은', '손', '타', '마', '린', '은', '▁검', '은', '타', '마', '린', '▁Sa', 'guin', 'us', '▁ni', 'ger', '▁의', '▁이', '명', '으로', '▁간', '주', '되었다', '▁2013', '년', '▁동', '부', '검', '은', '손', '타', '마', '린', '은', '▁분', '자', '생', '물', '학', '▁정보', '와', '▁', '털', '▁', '색', '의', '▁차이', '때', '문', '에', '▁마', '침', '내', '▁재', '검', '증', '되었다', '▁동', '부', '검', '은', '손', '타', '마', '린', '은', '▁3', '개의', '▁기', '아', '나', '▁기', '아', '나', '와', '▁아마', '존', '강', '▁하', '류', '▁사이', '의', '▁지역', '에서', '▁발견', '되는', '▁근', '연', '종', '▁', '붉', '은', '손', '타', '마', '린', '▁Sa', 'guin', 'us', '▁mida', 's', '▁', '싱', '구', '강', '과', '▁토', '칸', '칭', '스', '강', '▁사이에', '▁분', '포', '하는', '▁검', '은', '타', '마', '린', '과', '▁함께', '▁타', '마', '린', '속', '의', '▁', '붉', '은', '손', '타', '마', '린', '▁S', '▁mida', 's', '▁군', '에', '▁포함', '된다', '▁동', '부', '검', '은', '손', '타', '마', '린', '과', '▁검', '은', '타', '마', '린', '은', '▁종', '분', '화', '▁과정에서', '▁발생', '했고', '▁토', '칸', '칭', '스', '강', '이', '▁두', '▁종', '을', '▁지', '리', '적으로', '▁서로', '▁고', '립', '시', '켰', '다']\n"
     ]
    }
   ],
   "source": [
    "sent = preprocess_retrieval(contexts[41132])\n",
    "print(tokenizer.tokenize(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13f58880-2a39-4cd1-9bf5-ba884fdb839c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_list = [txt for txt, _ in counter.most_common(50)]\n",
    "len(common_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f3f0707-4fae-4c8c-8028-5e19ded06976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁', '의', '을', '에', '이', '은', '는', '년', '를', '로', '가', '에서', '▁이', '으로', '한', '고', '과', '인', '도', '와', '월', '리', '지', '일', '사', '스', '▁수', '기', '다', '▁있다', '어', '했다', '시', '르', '하였다', '▁그', '자', '하는', '라', '해', '▁전', '하고', '이다', '부', '하여', '군', '▁1', '▁가', '▁사', '대']\n"
     ]
    }
   ],
   "source": [
    "print(common_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d19826e-a89d-4bc4-b628-708db138cf08",
   "metadata": {},
   "outputs": [],
   "source": [
    "commons = common_list\n",
    "def tokenizer_func(corpus):\n",
    "    tokenized = tokenizer.tokenize(corpus)\n",
    "    filtered = [token for token in tokenized if token not in commons]\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ca46f1b-e0e0-426f-aa8f-8b6956260490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁동', '검', '손', '타', '마', '린', '▁18', '07', '▁다른', '▁타', '마', '린', '▁함께', '▁독일', '▁과학', '▁요', '▁호', '프', '만', '제', '크', '▁Johann', '▁Cent', 'uri', 'us', '▁Hoffman', 'nse', 'gg', '▁타', '마', '린', '속', '▁모', '식', '종', '▁기술', '▁나중에', '▁동', '검', '손', '타', '마', '린', '▁검', '타', '마', '린', '▁Sa', 'guin', 'us', '▁ni', 'ger', '▁의', '명', '▁간', '주', '되었다', '▁2013', '▁동', '검', '손', '타', '마', '린', '▁분', '생', '물', '학', '▁정보', '털', '색', '▁차이', '때', '문', '▁마', '침', '내', '▁재', '검', '증', '되었다', '▁동', '검', '손', '타', '마', '린', '▁3', '개의', '▁기', '아', '나', '▁기', '아', '나', '▁아마', '존', '강', '▁하', '류', '▁사이', '▁지역', '▁발견', '되는', '▁근', '연', '종', '붉', '손', '타', '마', '린', '▁Sa', 'guin', 'us', '▁mida', 's', '싱', '구', '강', '▁토', '칸', '칭', '강', '▁사이에', '▁분', '포', '▁검', '타', '마', '린', '▁함께', '▁타', '마', '린', '속', '붉', '손', '타', '마', '린', '▁S', '▁mida', 's', '▁군', '▁포함', '된다', '▁동', '검', '손', '타', '마', '린', '▁검', '타', '마', '린', '▁종', '분', '화', '▁과정에서', '▁발생', '했고', '▁토', '칸', '칭', '강', '▁두', '▁종', '▁지', '적으로', '▁서로', '▁고', '립', '켰']\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer_func(preprocessed[41132]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c3e7ae3e-833f-4da2-a3b4-00410c651b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_preprocess(corpus):\n",
    "    lst = [\"Original\", \"Preprocessed\", \"Filtered\"]\n",
    "    original = tokenizer.tokenize(corpus)\n",
    "    preprocessed = tokenizer.tokenize(preprocess_retrieval(corpus))\n",
    "    filtered = tokenizer_func(preprocess_retrieval(corpus))\n",
    "    sents = [original, preprocessed, filtered]\n",
    "    for i in range(3):\n",
    "        print('-'*50, lst[i] , '-'*50)\n",
    "        print(sents[i])\n",
    "        print(f\"Token Length : {len(sents[i])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ff051bb0-9096-4570-b313-caf5cfcce5e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------- Original --------------------------------------------------\n",
      "['▁이', '▁문서', '는', '▁나라', '▁목록', '이며', ',', '▁전', '▁세계', '▁206', '개', '▁나라', '의', '▁각', '▁현', '황', '과', '▁주', '권', '▁승인', '▁정보를', '▁개', '요', '▁형태', '로', '▁나', '열', '하고', '▁있다', '.', '▁이', '▁목록', '은', '▁명', '료', '화를', '▁위해', '▁두', '▁부분', '으로', '▁나', '뉘', '어', '▁있다', '.', '▁#', '▁첫', '▁번째', '▁부분', '은', '▁바', '티', '칸', '▁시', '국', '과', '▁팔', '레', '스타', '인', '을', '▁포함', '하여', '▁유', '엔', '▁등', '▁국제', '▁', '기구', '에', '▁가입', '되어', '▁국제', '적인', '▁승인', '을', '▁', '널', '리', '▁받았다', '고', '▁여기', '는', '▁195', '개', '▁나라', '를', '▁나', '열', '하고', '▁있다', '.', '▁#', '▁두', '▁번째', '▁부분', '은', '▁일부', '▁지역', '의', '▁주', '권을', '▁사실', '상', '▁(', '데', '▁', '팍', '토', ')', '▁행사', '하고', '▁있지만', ',', '▁아직', '▁국제', '적인', '▁승인', '을', '▁', '널', '리', '▁', '받', '지', '▁않았다', '고', '▁여기', '는', '▁11', '개', '▁나라', '를', '▁나', '열', '하고', '▁있다', '.', '▁두', '▁목록', '은', '▁모두', '▁가', '나', '다', '▁순', '이다', '.', '▁일부', '▁국가', '의', '▁경우', '▁국가', '로서', '의', '▁자격', '에', '▁논', '쟁', '의', '▁여부', '가', '▁있으며', ',', '▁이', '▁때문에', '▁이러한', '▁목록', '을', '▁', '엮', '는', '▁것은', '▁매우', '▁어렵', '고', '▁논란', '이', '▁생', '길', '▁수', '▁있는', '▁과정', '이다', '.', '▁이', '▁목록', '을', '▁구성', '하고', '▁있는', '▁국가', '를', '▁선정', '하는', '▁기준', '에', '▁대한', '▁정보는', '▁\"', '포', '함', '▁기준', '\"', '▁단', '락', '을', '▁통해', '▁설명', '하였다', '.', '▁나라', '에', '▁대한', '▁일반', '적인', '▁정보는', '▁\"', '국가', '\"', '▁문서', '에서', '▁설명', '하고', '▁있다', '.']\n",
      "Token Length : 226\n",
      "-------------------------------------------------- Preprocessed --------------------------------------------------\n",
      "['▁이', '▁문서', '는', '▁나라', '▁목록', '이며', '▁전', '▁세계', '▁206', '개', '▁나라', '의', '▁각', '▁현', '황', '과', '▁주', '권', '▁승인', '▁정보를', '▁개', '요', '▁형태', '로', '▁나', '열', '하고', '▁있다', '▁이', '▁목록', '은', '▁명', '료', '화를', '▁위해', '▁두', '▁부분', '으로', '▁나', '뉘', '어', '▁있다', '▁첫', '▁번째', '▁부분', '은', '▁바', '티', '칸', '▁시', '국', '과', '▁팔', '레', '스타', '인', '을', '▁포함', '하여', '▁유', '엔', '▁등', '▁국제', '▁', '기구', '에', '▁가입', '되어', '▁국제', '적인', '▁승인', '을', '▁', '널', '리', '▁받았다', '고', '▁여기', '는', '▁195', '개', '▁나라', '를', '▁나', '열', '하고', '▁있다', '▁두', '▁번째', '▁부분', '은', '▁일부', '▁지역', '의', '▁주', '권을', '▁사실', '상', '▁데', '▁', '팍', '토', '▁행사', '하고', '▁있지만', '▁아직', '▁국제', '적인', '▁승인', '을', '▁', '널', '리', '▁', '받', '지', '▁않았다', '고', '▁여기', '는', '▁11', '개', '▁나라', '를', '▁나', '열', '하고', '▁있다', '▁두', '▁목록', '은', '▁모두', '▁가', '나', '다', '▁순', '이다', '▁일부', '▁국가', '의', '▁경우', '▁국가', '로서', '의', '▁자격', '에', '▁논', '쟁', '의', '▁여부', '가', '▁있으며', '▁이', '▁때문에', '▁이러한', '▁목록', '을', '▁', '엮', '는', '▁것은', '▁매우', '▁어렵', '고', '▁논란', '이', '▁생', '길', '▁수', '▁있는', '▁과정', '이다', '▁이', '▁목록', '을', '▁구성', '하고', '▁있는', '▁국가', '를', '▁선정', '하는', '▁기준', '에', '▁대한', '▁정보는', '▁포함', '▁기준', '▁단', '락', '을', '▁통해', '▁설명', '하였다', '▁나라', '에', '▁대한', '▁일반', '적인', '▁정보는', '▁국가', '▁문서', '에서', '▁설명', '하고', '▁있다']\n",
      "Token Length : 206\n",
      "-------------------------------------------------- Filtered --------------------------------------------------\n",
      "['▁문서', '▁나라', '▁목록', '이며', '▁세계', '▁206', '개', '▁나라', '▁각', '▁현', '황', '▁주', '권', '▁승인', '▁정보를', '▁개', '요', '▁형태', '▁나', '열', '▁목록', '▁명', '료', '화를', '▁위해', '▁두', '▁부분', '▁나', '뉘', '▁첫', '▁번째', '▁부분', '▁바', '티', '칸', '▁시', '국', '▁팔', '레', '스타', '▁포함', '▁유', '엔', '▁등', '▁국제', '기구', '▁가입', '되어', '▁국제', '적인', '▁승인', '널', '▁받았다', '▁여기', '▁195', '개', '▁나라', '▁나', '열', '▁두', '▁번째', '▁부분', '▁일부', '▁지역', '▁주', '권을', '▁사실', '상', '▁데', '팍', '토', '▁행사', '▁있지만', '▁아직', '▁국제', '적인', '▁승인', '널', '받', '▁않았다', '▁여기', '▁11', '개', '▁나라', '▁나', '열', '▁두', '▁목록', '▁모두', '나', '▁순', '▁일부', '▁국가', '▁경우', '▁국가', '로서', '▁자격', '▁논', '쟁', '▁여부', '▁있으며', '▁때문에', '▁이러한', '▁목록', '엮', '▁것은', '▁매우', '▁어렵', '▁논란', '▁생', '길', '▁있는', '▁과정', '▁목록', '▁구성', '▁있는', '▁국가', '▁선정', '▁기준', '▁대한', '▁정보는', '▁포함', '▁기준', '▁단', '락', '▁통해', '▁설명', '▁나라', '▁대한', '▁일반', '적인', '▁정보는', '▁국가', '▁문서', '▁설명']\n",
      "Token Length : 135\n"
     ]
    }
   ],
   "source": [
    "explore_preprocess(contexts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ea635e13-bfb0-4721-bc81-d98b0832f617",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# from preprocess import tokenizer_filter\n",
    "\n",
    "with open(\"../data/tfidv.bin\", \"rb\") as file:\n",
    "    tfidfv = pickle.load(file)\n",
    "with open(\"../data/sparse_embedding.bin\", \"rb\") as file:\n",
    "    p_embedding = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0606d2e8-922c-469d-babd-0b3e95fc45d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_relevant_doc(query, k=1):\n",
    "    query_vec = tfidfv.transform([query])\n",
    "    result = query_vec * p_embedding.T\n",
    "    result = result.toarray()\n",
    "\n",
    "    sorted_result = np.argsort(result.squeeze())[::-1]\n",
    "    doc_score = result.squeeze()[sorted_result].tolist()[:k]\n",
    "    doc_indices = sorted_result.tolist()[:k]\n",
    "    return doc_score, doc_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1a451814-e25b-4a61-b874-0cbabd0ef960",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieval(query_or_dataset, topk):\n",
    "    doc_scores, doc_indices = get_relevant_doc(query_or_dataset, k=topk)\n",
    "    print(\"[Search query]\\n\", query_or_dataset, \"\\n\")\n",
    "\n",
    "    for i in range(topk):\n",
    "        print(f\"Top-{i+1} passage with score {doc_scores[i]:4f}\")\n",
    "        print(contexts[doc_indices[i]])\n",
    "\n",
    "    # return (doc_scores, [contexts[doc_indices[i]] for i in range(topk)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9f2aed0a-6984-47a7-afaf-3896272d71c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Search query]\n",
      " 트랜스포머 \n",
      "\n",
      "Top-1 passage with score 0.560885\n",
      "트랜스포머 실시영화 세계관에서는 1에서 처음등장하였다. 비클모드는 머스탱이다. 실사판 영화에서는 몸속의 프렌지를 데리고 다닌다 (언뜻 보면 사운드웨이브처럼 숨기고 다닌다)트랜스포머 실사판 3편에서도 잠깐 휠잭를 죽일때나온다. 그리고 군대쪽에서 총을 사격하자 그의 눈에 맞는다. 그리고 군대쪽에서 빌딩에서 내려오고 군대쪽에서 바리케이드의 발쪽에 이상한 폭파무기를 다리쪽에 심어놓고는 폭파되어 사망한다. 그후로 트랜스포머5(최후의 기사)에서도 부활하여 다시 출연한다. 하지만 초반에는 메가트론과 좀 나오다가 중간에 시가전을 펼칠때 그림록의 꼬리에 밀려나간 후로부터 나오질 않는다. 그 다음에는 스톤헨지에서 잠깐 메가트론,니트로제우스와 함께 포착되고 그 후로부터 등장이 없다.\n",
      "\n",
      "얼라인드 세계관에서 작품인 트랜스포머: 워 포 사이버트론에서는 플레이캐릭터로 등장한다.\n",
      "Top-2 passage with score 0.499154\n",
      "1969년, 그렇게 개발된 것이 2254E 컴프레서/리미터이다. 2254는 기본적으로 시그널이 게인의 변화를 주는 섹션을 지나서 다시 게인컨트롤 섹션에 영향을 주는 피드백 방식이었다. 2254의 특징은 총 4개의 트랜스포머로 가득한 게인스테이지 덩어리라는 것이다. 일단 인풋 게인 스테이지에서 첫 번째 트랜스포머가 들어온 신호에 색을 칠한다. 그 다음 신호는 게인 리덕션 유닛으로 넘어오는데 니브만의 다이오드 브릿지(diode bridges)방식은 사실 레벨 효율이 매우 떨어지는 방식이었다. 게인 리덕션 유닛을 지난 신호는 인풋신호에 비해 거의 40dB 가까이 떨어진채 두 번째 트랜스포머의 색을 묻힌 후 니브의 전매특허 BA283 아웃풋 앰프로 들어가게 된다. BA283에 포함된 총 세 번째 트랜스포머를 지나 원래의 라인신호 레벨을 되찾은 신호는 엔지니어 마음에 따라 리미터 사이드체인으로 들어가거나 말거나 중에 하나를 택한다. 리미터까지 들어가면 총 4개의 트랜스포머를 거치게 되는 것이다. 그로 인해 2254는 다른 기종에 비해 낮은 노이즈 대 시그널 비율을 가지고 있다. 그리고 특유의 색깔도 매우 독특하다. 이것이 2254만의 매력이다. 게인리덕션의 성향은 비단같은 스무스함을 가지고 있다. 다양한 신호에 대해서 레벨 컨트롤도 자연스러운 편이다. 그렇지만 트랜스포머 덩어리와 BA283 앰프의 색을 잔뜩 입혀주었기에 여전히 클래식 컴프레서로서의 가치를 이어나가고 있는 것이다. 기본적으로 느린 편인 어택은 고정되어 있다. 2254는 대표적인 피드백타입 컴프레서로 불리는 만큼 반응이 느린 컴프레서이다. 릴리즈를 자동으로 놓으면 릴리즈타임뿐만 아니라 어택타임까지 시그널에 맞추어 속도가 자동으로 조절된다. 자연스러운 스무스니스는 바로 오토 세팅에서 나오는 것이다. 하지만 트랜지언트 소스의 경우에는 다이나믹 디스토션이 생길 가능성이 크다. 다이나믹 디스토션 효과를 얻고자 한다면 그렇게 쓸수도 있지만 펀치감이 파괴될 수도 있으니 주의해야 한다.\n",
      "Top-3 passage with score 0.460424\n",
      "매년, 해즈브로는 명예의 전당의 인간 부분에 입성할 개인을 선정한다. 해즈브로는 또한 명예의 전당의 트랜스포머 부분에 소중히 간직하여 자격이 있다고 느끼는 특정 캐릭터를 선택한다. 명예의 전당의 목적상, 등장인물들은 다른 연속성들 사이에서 차별화되지 않는다. 캐릭터 일대기는 캐릭터가 해즈브로의 현재 통일된 연속성에 표현되어 있음을 반영하는 경향이 있었다.\n",
      "\n",
      "해즈브로는 팬들 선택 입성을 위해 다양한 트랜스포머 팬 사이트에서 추가 후보 지명을 요청한다. 상위 5명의 후보자는 명예의 전당에 선출 될 자격이 있으며 투표는 공식 트랜스포머 웹 사이트에서 4월에 열린다. 수상자는 명예의 전당 입성식에서 발표된다.\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(retrieval(\"트랜스포머\", 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46ab12d-8e11-45cc-93f6-3ea69eb4a391",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
