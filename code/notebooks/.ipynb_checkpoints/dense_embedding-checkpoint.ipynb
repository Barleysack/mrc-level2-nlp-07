{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "116de6d1-b38a-48f2-b17c-294cc9511770",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from pprint import pprint\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from datasets import load_dataset, load_from_disk\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    BertModel, BertPreTrainedModel,\n",
    "    AdamW, get_linear_schedule_with_warmup,\n",
    "    TrainingArguments, AutoModel,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6743c0c-76fc-451d-b63a-1dbb06ca50e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RobertaEncoder(AutoModel):\n",
    "    def __init__(self, config):\n",
    "        super(RobertaEncoder, self).__init__(config)\n",
    "\n",
    "        self.roberta = AutoModel(config)\n",
    "        self.init_weights()\n",
    "      \n",
    "    def forward(self, input_ids,  attention_mask=None, token_type_ids=None): \n",
    "\n",
    "        outputs = self.roberta(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "        \n",
    "        pooled_output = outputs[1]\n",
    "        return pooled_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0261854e-2a5b-458a-8e03-4b5ddbb3217e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b65f5582b36441759035fecb286ac910",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=2244861551.0, style=ProgressStyle(descr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_checkpoint = \"xlm-roberta-large\"\n",
    "p_encoder = RobertaEncoder.from_pretrained(model_checkpoint)\n",
    "q_encoder = RobertaEncoder.from_pretrained(model_checkpoint)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    p_encoder.cuda()\n",
    "    q_encoder.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ef0c9261-c342-4858-ae09-a4318103e0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseRetrieval:\n",
    "    def __init__(self, args, dataset, num_neg, tokenizer, p_encoder, q_encoder):\n",
    "\n",
    "        self.args = args\n",
    "        self.dataset = dataset\n",
    "        self.num_neg = num_neg\n",
    "\n",
    "        self.tokenizer = tokenizer\n",
    "        self.p_encoder = p_encoder\n",
    "        self.q_encoder = q_encoder\n",
    "\n",
    "        self.prepare_in_batch_negative(num_neg=num_neg)\n",
    "\n",
    "    def prepare_in_batch_negative(self, dataset=None, num_neg=2, tokenizer=None):\n",
    "\n",
    "        if dataset is None:\n",
    "            dataset = self.dataset\n",
    "\n",
    "        if tokenizer is None:\n",
    "            tokenizer = self.tokenizer\n",
    "\n",
    "        # 1. In-Batch-Negative 만들기\n",
    "        # CORPUS를 np.array로 변환해줍니다.\n",
    "        corpus = np.array(list(set([example for example in dataset[\"context\"]])))\n",
    "        p_with_neg = []\n",
    "\n",
    "        for c in dataset[\"context\"]:\n",
    "            while True:\n",
    "                neg_idxs = np.random.randint(len(corpus), size=num_neg)\n",
    "\n",
    "                if not c in corpus[neg_idxs]:\n",
    "                    p_neg = corpus[neg_idxs]\n",
    "\n",
    "                    p_with_neg.append(c)\n",
    "                    p_with_neg.extend(p_neg)\n",
    "                    break\n",
    "\n",
    "        # 2. (Question, Passage) 데이터셋 만들어주기\n",
    "        q_seqs = tokenizer(dataset[\"question\"], padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "        p_seqs = tokenizer(p_with_neg, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "        max_len = p_seqs[\"input_ids\"].size(-1)\n",
    "        p_seqs[\"input_ids\"] = p_seqs[\"input_ids\"].view(-1, num_neg+1, max_len)\n",
    "        p_seqs[\"attention_mask\"] = p_seqs[\"attention_mask\"].view(-1, num_neg+1, max_len)\n",
    "        # p_seqs[\"token_type_ids\"] = p_seqs[\"token_type_ids\"].view(-1, num_neg+1, max_len)\n",
    "\n",
    "        train_dataset = TensorDataset(\n",
    "            p_seqs[\"input_ids\"], p_seqs[\"attention_mask\"], # p_seqs[\"token_type_ids\"], \n",
    "            q_seqs[\"input_ids\"], q_seqs[\"attention_mask\"], # q_seqs[\"token_type_ids\"]\n",
    "        )\n",
    "\n",
    "        self.train_dataloader = DataLoader(\n",
    "            train_dataset,\n",
    "            shuffle=True,\n",
    "            batch_size=self.args.per_device_train_batch_size\n",
    "        )\n",
    "\n",
    "        valid_seqs = tokenizer(\n",
    "            dataset[\"context\"],\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        passage_dataset = TensorDataset(\n",
    "            valid_seqs[\"input_ids\"],\n",
    "            valid_seqs[\"attention_mask\"],\n",
    "            # valid_seqs[\"token_type_ids\"]\n",
    "        )\n",
    "        self.passage_dataloader = DataLoader(\n",
    "            passage_dataset,\n",
    "            batch_size=self.args.per_device_train_batch_size\n",
    "        )\n",
    "\n",
    "\n",
    "    def train(self, args=None):\n",
    "        if args is None:\n",
    "            args = self.args\n",
    "        batch_size = args.per_device_train_batch_size\n",
    "\n",
    "        # Optimizer\n",
    "        no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "        optimizer_grouped_parameters = [\n",
    "            {\"params\": [p for n, p in self.p_encoder.named_parameters() if not any(nd in n for nd in no_decay)], \"weight_decay\": args.weight_decay},\n",
    "            {\"params\": [p for n, p in self.p_encoder.named_parameters() if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0},\n",
    "            {\"params\": [p for n, p in self.q_encoder.named_parameters() if not any(nd in n for nd in no_decay)], \"weight_decay\": args.weight_decay},\n",
    "            {\"params\": [p for n, p in self.q_encoder.named_parameters() if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0}\n",
    "        ]\n",
    "        optimizer = AdamW(\n",
    "            optimizer_grouped_parameters,\n",
    "            lr=args.learning_rate,\n",
    "            eps=args.adam_epsilon\n",
    "        )\n",
    "        t_total = len(self.train_dataloader) // args.gradient_accumulation_steps * args.num_train_epochs\n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            optimizer,\n",
    "            num_warmup_steps=args.warmup_steps,\n",
    "            num_training_steps=t_total\n",
    "        )\n",
    "\n",
    "        # Start training!\n",
    "        global_step = 0\n",
    "\n",
    "        self.p_encoder.zero_grad()\n",
    "        self.q_encoder.zero_grad()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        train_iterator = tqdm(range(int(args.num_train_epochs)), desc=\"Epoch\")\n",
    "        # for _ in range(int(args.num_train_epochs)):\n",
    "        for _ in train_iterator:\n",
    "\n",
    "            with tqdm(self.train_dataloader, unit=\"batch\") as tepoch:\n",
    "                for batch in tepoch:\n",
    "\n",
    "                    p_encoder.train()\n",
    "                    q_encoder.train()\n",
    "            \n",
    "                    targets = torch.zeros(batch_size).long() # positive example은 전부 첫 번째에 위치하므로\n",
    "                    targets = targets.to(args.device)\n",
    "\n",
    "                    p_inputs = {\n",
    "                        \"input_ids\": batch[0].view(batch_size * (self.num_neg + 1), -1).to(args.device),\n",
    "                        \"attention_mask\": batch[1].view(batch_size * (self.num_neg + 1), -1).to(args.device),\n",
    "                        # \"token_type_ids\": batch[2].view(batch_size * (self.num_neg + 1), -1).to(args.device)\n",
    "                    }\n",
    "            \n",
    "                    q_inputs = {\n",
    "                        \"input_ids\": batch[2].to(args.device),\n",
    "                        \"attention_mask\": batch[3].to(args.device),\n",
    "                        # \"token_type_ids\": batch[5].to(args.device)\n",
    "                    }\n",
    "\n",
    "                    # (batch_size*(num_neg+1), emb_dim)\n",
    "                    p_outputs = self.p_encoder(**p_inputs)\n",
    "                    # (batch_size*, emb_dim)\n",
    "                    q_outputs = self.q_encoder(**q_inputs)\n",
    "\n",
    "                    # Calculate similarity score & loss\n",
    "                    p_outputs = p_outputs.view(batch_size, -1, self.num_neg+1)\n",
    "                    q_outputs = q_outputs.view(batch_size, 1, -1)\n",
    "\n",
    "                    sim_scores = torch.bmm(q_outputs, p_outputs).squeeze()  #(batch_size, num_neg + 1)\n",
    "                    sim_scores = sim_scores.view(batch_size, -1)\n",
    "                    sim_scores = F.log_softmax(sim_scores, dim=1)\n",
    "\n",
    "                    loss = F.nll_loss(sim_scores, targets)\n",
    "                    tepoch.set_postfix(loss=f\"{str(loss.item())}\")\n",
    "\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    scheduler.step()\n",
    "\n",
    "                    self.p_encoder.zero_grad()\n",
    "                    self.q_encoder.zero_grad()\n",
    "\n",
    "                    global_step += 1\n",
    "\n",
    "                    torch.cuda.empty_cache()\n",
    "\n",
    "                    del p_inputs, q_inputs\n",
    "\n",
    "\n",
    "    def get_relevant_doc(self, query, k=1, args=None, p_encoder=None, q_encoder=None):\n",
    "    \n",
    "        if args is None:\n",
    "            args = self.args\n",
    "\n",
    "        if p_encoder is None:\n",
    "            p_encoder = self.p_encoder\n",
    "\n",
    "        if q_encoder is None:\n",
    "            q_encoder = self.q_encoder\n",
    "\n",
    "        with torch.no_grad():\n",
    "            p_encoder.eval()\n",
    "            q_encoder.eval()\n",
    "\n",
    "            q_seqs_val = self.tokenizer(\n",
    "                [query],\n",
    "                padding=\"max_length\",\n",
    "                truncation=True,\n",
    "                return_tensors=\"pt\"\n",
    "            ).to(args.device)\n",
    "            q_emb = q_encoder(**q_seqs_val).to(\"cpu\")  # (num_query=1, emb_dim)\n",
    "\n",
    "            p_embs = []\n",
    "            for batch in self.passage_dataloader:\n",
    "\n",
    "                batch = tuple(t.to(args.device) for t in batch)\n",
    "                p_inputs = {\n",
    "                    \"input_ids\": batch[0],\n",
    "                    \"attention_mask\": batch[1],\n",
    "                    # \"token_type_ids\": batch[2]\n",
    "                }\n",
    "                p_emb = p_encoder(**p_inputs).to(\"cpu\")\n",
    "                p_embs.append(p_emb)\n",
    "\n",
    "        # (num_passage, emb_dim)\n",
    "        p_embs = torch.stack(p_embs, dim=0).view(len(self.passage_dataloader.dataset), -1)\n",
    "\n",
    "        dot_prod_scores = torch.matmul(q_emb, torch.transpose(p_embs, 0, 1))\n",
    "        rank = torch.argsort(dot_prod_scores, dim=1, descending=True).squeeze()\n",
    "\n",
    "        return rank[:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fe7bf4d-b4bb-4ae3-aa01-bc7651aa698b",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir=\"dense_retireval\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3281aa81-da50-4618-a3d6-dcb00a89b22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = load_from_disk(\"../data/train_dataset/train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6126c30b-f7df-48a9-b969-13a73257db78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'미국 상의원 또는 미국 상원(United States Senate)은 양원제인 미국 의회의 상원이다.\\\\n\\\\n미국 부통령이 상원의장이 된다. 각 주당 2명의 상원의원이 선출되어 100명의 상원의원으로 구성되어 있다. 임기는 6년이며, 2년마다 50개주 중 1/3씩 상원의원을 새로 선출하여 연방에 보낸다.\\\\n\\\\n미국 상원은 미국 하원과는 다르게 미국 대통령을 수반으로 하는 미국 연방 행정부에 각종 동의를 하는 기관이다. 하원이 세금과 경제에 대한 권한, 대통령을 포함한 대다수의 공무원을 파면할 권한을 갖고 있는 국민을 대표하는 기관인 반면 상원은 미국의 주를 대표한다. 즉 캘리포니아주, 일리노이주 같이 주 정부와 주 의회를 대표하는 기관이다. 그로 인하여 군대의 파병, 관료의 임명에 대한 동의, 외국 조약에 대한 승인 등 신속을 요하는 권한은 모두 상원에게만 있다. 그리고 하원에 대한 견제 역할(하원의 법안을 거부할 권한 등)을 담당한다. 2년의 임기로 인하여 급진적일 수밖에 없는 하원은 지나치게 급진적인 법안을 만들기 쉽다. 대표적인 예로 건강보험 개혁 당시 하원이 미국 연방 행정부에게 퍼블릭 옵션(공공건강보험기관)의 조항이 있는 반면 상원의 경우 하원안이 지나치게 세금이 많이 든다는 이유로 퍼블릭 옵션 조항을 제외하고 비영리건강보험기관이나 보험회사가 담당하도록 한 것이다. 이 경우처럼 상원은 하원이나 내각책임제가 빠지기 쉬운 국가들의 국회처럼 걸핏하면 발생하는 의회의 비정상적인 사태를 방지하는 기관이다. 상원은 급박한 처리사항의 경우가 아니면 법안을 먼저 내는 경우가 드물고 하원이 만든 법안을 수정하여 다시 하원에 되돌려보낸다. 이러한 방식으로 단원제가 빠지기 쉬운 함정을 미리 방지하는 것이다.날짜=2017-02-05'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]['context']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "09744621-acb3-4204-8462-22ce59af0249",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3952"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c4dd9a92-b136-4653-9c23-d824f6c31967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['김 바르바라(金巴巴拉, 1805년 ~ 1839년 5월 27일)는 조선의 천주교 박해 때에 순교한 한국 천주교의 103위 성인 중에 한 사람이다. 세례명은 바르바라(Barbara)이다.\\\\n\\\\n성녀 김 바르바라는 감옥에서 질병으로 죽은 순교자들 중에 한 명이다. 현석문 가롤로의 《기해일기》에 따르면, 60명 이상의 사람들이 감옥에서 고문과 질병으로 죽었다.\\\\n\\\\n사실, 고문의 고통도 끔찍했지만, 매일의 수감 생활은 보다 더 심각하여 견딜 수 없었다. 그곳에는 온갖 종류의 고문을 견디며 용감히 신앙을 증언한 많은 사람들이 있었지만, 결국 굶주림과 목마름 때문에 굴복했다. 고작 하루에 두 줌의 밥만이 배식된 죄수들은 종종 그들 밑에 깔려 있는 짚을 뜯어 먹었다. 또한 많은 수의 사람들이 작은 옥방에 수감되었으므로, 질병이 생기고 빠르게 전염되는 것을 피할 수 없었다. 후일에 순교자로 죽은 다블뤼 주교는 감옥의 상황에 대하여 이렇게 기술했다.\\\\n\\\\n우리 천주교인들은 너무 빽빽히 수감되었기 때문에 다리를 펴고 자는 것 조차 하지 못하였다. 수감 생활의 고통에 비하면 고문의 고통은 아무것도 아니다. 설상가상으로 그들의 썩은 상처에서 풍기는 악취는 견딜 수 없었고 장티푸스가 발발해 몇 일 동안 여러 명이 사망하였다.\\\\n\\\\n김 바르바라와 같은 사람들은 수감 생활의 극심한 고통을 경험하였다. 감옥에서 그들은 망나니의 칼로부터 순교의 영광을 얻을 수 있을 만큼 오래 살 수 있을지가 가장 큰 걱정이었다.', '1962년 수에오카는 중립적 돌연변이가 광범위하게 존재하는 것을 발견하였다. 1968년 기무라 모토는 이를 바탕으로 중립 진화 이론을 발표하였다. 기무라의 이론은 분자생물학 학자들에게 널리 알려졌으며 1969년 젝 레스터 킹과 토머스 휴즈 주크스는 기무라의 이론을 바탕으로 《비 다윈 진화이론》 을 발표하였다.\\\\n\\\\n기무라는 한 생물 종의 게놈에서 나타나는 돌연변이의 대다수는 개체의 생존과 재생산에 이익을 가져다주지도 않고 그렇다고 불리한 것도 아닌 \"중립적\"인 것이라고 보았다. 즉 DNA 단위에서 대부분의 돌연변이는 개체의 적응도에 대해 중립적이다. 중립 진화 이론은 아미노산의 생성을 지시하는 코돈 가운데 일부가 더 이상 독립적인 의미를 갖지 못하는 퇴보를 보인다는 점에서 출발한다. 예를 들어 GCC와 GCA는 모두 알라닌의 생성을 지시한다. 여기에 더해 DNA 서열의 대다수 구간은 유전정보로 발현되지 않는 이른바 \"침묵 구간\"(비부호화 DNA)이다. 이것은 당시에도 생물학에서 상식적으로 알고 있던 내용이다. 기무라는 이러한 자명한 사실에서 출발하여 아무도 생각하지 못하였던 독창적인 이론을 제시하였다. 대부분의 비부호화 DNA가 중립적이라면 DNA의 돌연변이 역시 대부분 중립적이어야 한다.\\\\n\\\\n중립 진화 이론은 생물 진화의 주요 원인이 중립적인 대립형질이 보이는 유전자 부동에 의한 것으로 본다. 유전자의 자연적인 돌연변이에 의해 발생된 특정한 유전형질은 세대를 거치면서 유전자 부동을 통해 자식 세대로 유전된다. 단세포 생물을 이용한 실험에서 이러한 대립형질의 발현빈도가 보이는 무작위 행보는 실시간으로 관찰될 수 있다. 반면, 유성 생식을 하는 다세포 생물의 경우 이러한 대립형질의 유전자 부동은 생식체를 통하여 자식 세대에 전달되므로 배아의 발생 과정에서 집단 내 대립형질의 유전자 부동이 관찰된다. 이러한 유전자 부동에 따라 세대를 거쳐 대립형질의 발현빈도가 계속하여 바뀌게 되고 어떠한 대립형질은 고착되게 된다. 이렇게 고착된 대립형질은 더 이상 발현빈도가 변하지 않음으로 세대를 거쳐 누적되고 이러한 과정의 반복이 결국 진화로 나타난다.', '1802년으로 거슬러 올라가, 청각 장애를 우려해 \"하이리겐슈타트의 유서\"를 쓴 베토벤은, 이후 자신이 안고 있는 난청이 악화일로로 치닫고 있었음에도, 피아노 협주곡이라는 장르에 있어서 전작 피아노협주곡 4번까지는 초연시 베토벤 스스로 독주 피아노를 맡아왔다. 그러나 이 악곡의 작곡 과정에서 초래된 프랑스군의 폭격음은 가뜩이나 진행중이던 그의 난청을 보다 중증화 시켜버렸고, 결국은 이 악곡의 초연에 피아노 독주자로 참여하는 것을 포기, 다른 피아니스트에게 독주를 맡기는 상황에 이르게 되었다. 그렇다고는 해도, 이 악곡에 대한 청중의 반응은 무덤덤 했다.\\\\n\\\\n초연은 1811년 1월 13일, 롭코비츠 후작궁에서 열린 정기연주회에서 베토벤의 제자이자, 후원자였던 루돌프 대공의 독주에 의해 비공개로 실시되었다(독일에서의 첫 출판을 2,3개월 앞 둔 상황이었다.). 그리고 같은 해 11월 28일, 라이프치히의 게반트하우스 연주회에서 요한 필리프 크리스티안 슐츠의 지휘와 프리드리히 슈나이더의 독주에 의한 첫 공개 초연이 이루어졌으며, 이어 1812년 2월 12일에는 빈의 쾰른토나토아 극장에서, 같은 베토벤의 제자 중 한 명인 카를 체르니의 독주에 의한 초연이 이루어졌다. 이후 이 악곡은 베토벤의 생존 중에 두 번 다시 연주되지 않았다. 게다가 베토벤은 새로운 피아노 협주곡 마저도 생존해 있는 동안 결코 써 내지 않았다. 후년에 이르러 이 악곡은 프란츠 리스트가 즐겨 연주하기 시작하면서 널리 알려지기 시작했고, 걸작 반열에 들어서게 되었다.', \"러시아 제국 시기 동안, 크렘린 궁은 대관식과 같은 중대한 행사를 하는데에 쓰이기는 했으나, 그 외의 거의 대부분의 기간 동안에는 1773년동안 거의 버려져 있었다. 하지만 예카테리나 대제가 건축가들을 시켜 그녀의 새 궁전을 크렘린 궁에 지으라고 명령하며 이 상황이 달라지게 된다. 건축가들은 신고전주의 양식의 궁전을 엄청나게 큰 규모로 지었고, 이 규모로 인하여 크렘린 궁전의 성벽을 포함, 원래 지어져 있던 상당수의 궁전 건물들이 부지 확보를 위하여 철거될 수 밖에 없었다. 이 궁전 공사는 예산 문제로 인하여 잠시 차일피일 미루어지다가, 이후 본격적으로 공사를 시작하여 의회 건물들이 지어지며 전형적인 관청의 형식을 띠게 되었다. 제정 시기 동안, 크렘린 궁의 성벽은 전통을 따라 흰색으로 칠해져 있었다.\\\\n\\\\n나폴레옹의 프랑스 군대와의 전쟁을 겪을 동안, 크렘린 궁은 1812년 9월부터 10월까지 약 1달 정도 프랑스 군의 지배 하에 있었다. 나중에 나폴레옹이 퇴각할 적에, 그는 크렘린 궁에 있는 모든 건물들을 불사를 것을 명했고, 이로 인하여 크렘린 성벽을 포함하여 무기고, 궁정과 같은 건물들 거의 대부분이 거의 반파되었다. 폭발과 함께 발생한 화재는 거의 3일 가까이 지속되었으나, 이후 비가 내리면서 점차 꺼져갔다. 1816년에서 1819년까지 복원공사가 진행되었고, 알렉산드르 1세의 재위기간 하에 크렘린 성내에 있었던 구 건물들 절대다수가 신고딕 양식의 건물들로 새롭게 세워졌다. 하지만 알렉산드르 1세가 원래 세워져있던 건물들 거의 대부분을 '미사용' 혹은 '불필요한' 건축물로 판단하여, 현재 크렘린 궁전에서 이 이전의 건물들을 쉽게 찾아보기는 어렵다. 이후 크렘린 궁전은 상트페테르부르크에 있는 겨울 궁전과 쌍벽을 이루는 러시아의 대표적인 궁전들 중 하나로 급격히 그 위세가 성장하였고, 특히 바로크 양식의 겨울 궁전에 염증을 느낀 니콜라이 1세가 크렘린 궁전을 대대적으로 보수하면서 그 내관이 훨씬 더 화려해졌다.\\\\n\\\\n1851년 이후에는 크렘린 궁전에 특별한 공사가 더해지지 않았다. 다만 알렉산드르 2세의 기념비와 1905년에 암살당한 세르게이 알렉산드로비치가 죽은 자리를 표시하는 석판이 깔린 것을 제외하면 크렘린 궁전은 거의 아무 변화가 없었다. 참고로 이 기념비석들은 볼셰비키가 크렘린궁을 점령한 이후 모두 파괴되었다.\", \"1978년 성균관대학교 사회학과에 입학하였는데 입학하자마자 그는 학생운동에 투신하였고 이로 인해 경찰의 수배명단에 올랐다. 포항에서 도피하던 중 1979년 10·26 사태를 접하고, 곧바로 상경하여 전국 총학생회 부활 준비위원회 상임위원장을 맡아 활발한 활동을 전개하였다. 그의 뜻대로 총학생회는 부활하고 있었지만 1980년 5·17 군사 정변 직후 신군부에게 검거되었다. 검거 후 신군부에서 내건 조건은 군 입대 또는 투옥을 선택하라는 것이었다. 그는 군 입대를 결심하고 해병대를 지원하여 헌병으로 사병 복무하였다. 전역 후 복학하여 1984년에 성균관대학교를 졸업하고 본격적인 민주화 운동을 펼치게 된다. 정병국은 수배를 받으면서도 많은 활동을 하였다. '세인출판사'를 운영하며 서울 지역 대학교 총학생회에서 필요로 하는 거의 모든 인쇄물들을 공급하였고 군사 정권과 투쟁하고 있는 학생들을 꾸준히 지원하였다. 그러다 1987년 6월에 국가안전기획부에 의해 검거되어 고문을 받던 중 6·29 선언을 접하게 되었다. 징역 1년 6개월의 실형을 선고받았으나 6·29 선언으로 인하여 집행유예로 풀려날 수 있었다. 그 때 도움을 준 사람들은 그의 변론을 자청한 민주화추진협의회 소속 변호사들이었다.\", \"스페인어로 '토레 (torre)'는 탑을 뜻하며, '온' (ón)은 엄청난 크기나 높이를 강조할 때 흔히 붙이는 접미사다. 따라서 '토레혼 (torrejón)'이라는 말은 '거대한 탑'이라고 해석해볼 수 있다. 토레혼데아르도스라는 지명이 언제부터 유래된 것인지는 명확히 밝혀진 바가 없으나 알칼라데에나레스에 성벽이 지어졌던 시기와 연관지어 본다면 대략 12세기 경으로 거슬러 올라갈 수 있다. \\\\n\\\\n1843년 에스파르테로 왕자에게 반기를 들고 난이 일어나면서, 라몬 나르바에스 장군과 안토니오 세오아네 상원의원이 이곳에서 짧은 전투를 벌이기도 했다. \\\\n\\\\n스페인 내전 초반에는 토레혼과 파라쿠에요스델하라마 사이에 있는 들판에서 공화파 민병대가 프랑코파 군인들과 그를 지지하는 시민들(로 추정)을 사살하는 사건이 벌어졌는데 이를 파라쿠에요스 대학살이라고 부른다.\\\\n\\\\n토레혼데아르도스에서 태어난 유명인으로는 옛날 토론토 랩터스에서 포워드로 뛰었던 농구선수 호르게 가르바호사, 레알 마드리드 FC 미드필더 구티, 오리건주지사 케이트 브라운, 그리고 프로레슬러 글렌 제이컵스 (링네임으로 케인)이 있다. 브라운과 제이컵스는 아버지가 미 공군 출신으로 이곳 기지에서 복무했었기에 토레혼에서 태어난 것이다.\", '공전(公轉)은 한 천체가 다른 천체 주위를 원이나 타원 궤도를 따라 도는 것을 말한다.\\\\n\\\\n천문학에서 일컫는 공전은 은하 내의 항성들이 은하 중심에 대하여 도는 것도 공전이라고 부른다.\\\\n\\\\n다만 공전 운동 중심에 항상 천체가 존재하지는 않는다. 예를 들면 질량 차이가 크지 않은 2개의 항성이 쌍성계를 구성하고 있는 경우, 항성계의 질량 중심은 두 별 사이의 공간에 존재한다.\\\\n\\\\n공전의 주체는 항성이나 행성, 위성에 국한되지 않고 티끌이나 가스 등인 경우도 많이 있다. 태양계의 경우 목성, 토성, 천왕성의 고리는 먼지나 얼음 등이 작은 입자 형태로 되어 있으며 이런 입자들이 행성 주위를 돌고 있는 것으로 생각된다. 블랙홀의 경우 빨려 들어가는 물질이 블랙홀 주위에 강착 원반을 형성하여 공전 운동을 하고 있다.\\\\n\\\\n공전 운동의 원천이 되는 중력원의 질량이 일정하다고 가정하면, 행성 공전주기의 제곱이 궤도장반경의 세제곱에 비례한다는 조화의 법칙이 성립된다. 은하 내부를 도는 항성의 공전 운동의 경우 은하 물질이 은하 중심부터 바깥 영역에 걸쳐 연속적으로 분포하고 있기 때문에, 항성의 공전 운동은 은하 중심에서 그 항성 위치까지 분포하는 은하 물질 전체에서 받는 중력에 의해 정해진다.', '소마 가문은 가마쿠라 시대부터 무쓰 국 나메카타 군과 우다 군에 이주하여 메이지 시대에 이르기까지 오랫동안 그 지역을 통치했으나, 에도 시대 초기에 한때 위기를 맞이하였다.\\\\n\\\\n1600년, 세키가하라 전투 당시 소마 가문의 당주 소마 요시타네는 중립을 고수하였다. 이시다 미쓰나리와의 연관도 있었고, 서군(西軍)인 사타케 가문과도 인척관계에 있었기 때문이다. 하지만 이로 인해 도쿠가와 이에야스는 소마 가문을 서군으로 간주하고 1602년, 사타케 가문과 함께 그 영지를 몰수하였다. 구보타 번으로 옮겨간 사타케 요시노부는 소마 가문에게 아키타의 1만 석 영지를 제공하며 옮겨올 것을 권유하였으나, 요시타네의 아들 소마 도시타네는 \\'지금, 집안을 보전하고 배고픔과 추위를 면하자고 사타케의 밑으로 들어가 가문의 이름을 더럽히는 것은 한심한 일\\'이라며 에도로 직접 찾아가 영지 몰수의 철회를 호소했다. 여기에 도쿠가와의 가신 혼다 마사노부의 설득이 힘을 실어주면서, 결국 요시타네는 책임을 지고 은거하며, 본래 영지는 도시타네에게 돌려주는 것으로 결론이 났다. 이리하여 소마 가문은 가까스로 그 본거지를 지켜내게 되었으니 소마 나카무라 번이 이로써 성립되었다.\\\\n\\\\n초대 번주 도시타네와 2대 번주 요시타네 대에는 나카무라 성의 축성, 가신들의 재배치, 토지 조사 등이 이루어져 번의 체제를 갖추어나갔다. 또 이때 전통적으로 행해지던 소마 말 쫓아 축제(소마 노마오이) 행사에 무예의 색채를 더하여 오늘날의 형식을 완성하였다. 덴메이 대기근 때 번은 큰 타격을 입었으며, 위기를 타개하기 위해 금지되어 있던 이민으로 호쿠리쿠 지방으로부터 받아들이기도 하였다.\\\\n\\\\n5대 번주 마사타네 때 후다이격이 되었고, 7대 다카타네 때 후다이 다이묘가 되었다. 이후 막부 말기까지 후다이 다이묘로 유지되었다.\\\\n\\\\n1868년 보신 전쟁에서는 나카무라 번은 남쪽 이와키타이라 번와 북쪽 센다이 번 함께 오우에쓰 열번 동맹에 참가하고 메이지 정부와 적대했지만 패배했다. 보신 전쟁 후 번주 소마 씨의 나카무라 성은 메이지 정부의 \"지배 거점\"이되었다.', '〈반전반핵가(反戰反核歌)〉는 1986년에 발표된 대한민국의 노래이다. 서울대 노래패 메아리의 창립 회원이었던 박치음이 작사와 작곡을 모두 맡았다.\\\\n\\\\n1980년대 후반의 집회와 시위에서 큰 인기를 누렸다. \"제국의 발톱이 이 강토 이 산하를\"라는 가사로 시작하며, \"민족의 생존이 핵폭풍 전야에 섰다\"는 절박함과 \"이 목숨 다바쳐\" 싸우겠다는 각오를 피력해 비장한 느낌을 준다. 특히 노래를 시작하기 전에 \"반전 반핵, 양키 고 홈\"이라는 구호를 리듬감 있게 외치는 부분이 인상적이다. 이 구호는 노래 마지막 부분에서도 반복된다.\\\\n\\\\n당시 서울대학교 대학원 박사 과정에 재학 중이던 박치음은 1986년 봄에 서울대생 김세진이 전방입소에 반대하며 분신자살한 사건에 충격을 받고 이 노래를 만들었다. 박사 과정을 마치고 순천대학교 교수로 부임한 박치음은 이 노래가 대학가에서 공전의 히트를 기록하면서 곤란한 처지에 놓이기도 했다.\\\\n\\\\n\"미국\"이라는 표현은 직접 등장하지 않으나 반미주의 정서가 듬뿍 담겨 있으며, 광주 민주화 운동 이후의 미국에 대한 배신감이나 1980년대 중반 이후의 한국 현대사와 제3세계 역사에 대한 새로운 인식과 공감대를 이루어 널리 사랑받았다는 평가가 있다.', '카르타고 신성대는 기원전 4세기 동안에 카르타고의 군대에 복무한 카르타고 시민 보병대를 일컫는 그리스 역사가들이 사용한 명칭이다. 이러한 보병으로서 카르타고 시민들이 싸우는 것은 카르타고 시민들은 일반적으로 장교나 카르타고인들로 이뤄진 중무장 기병대에서 복무했기에 흔치 않은 일이었다; 카르타고 병력의 대부분은 보통은 용병, 동맹 지역 공동체 (포에니인 식민지 출신들로 추정)의 보병, 피정복민 징집병들로 이뤄졌다.\\\\n\\\\n“신성대”는 “출신, 부유함, 평판등 모두 열등하지 않은“ 2000-3000명의 소규모 중무장 보병들로 이뤄졌다. 어린 시절부터 강력한 팔랑크스 창병이 되기 위해 훈련된 이들은 카르타고의 부유한 가문 출신들이었으므로 높은 품질의 무기와 장비를 갖출 여유가 있었다. 그들은 그리스 방식으로 조직된 전통적인 팔랑크스 방식으로 싸웠다.\\\\n\\\\n기원전 341년 시칠리아의 크리미수스 전투에서 “신성대”는 잘 구성된 팔랑크스처럼 싸웠다. 그리고 완패를 당했다. 2,000명의 시민 병력들이 (아마 유사한 부대) 기원전 311년에 기록되었고, 마지막으로 시민 병력들은 해외에서 기록되었다. 기원전 310년에 개혁을 거쳤다고 나타난 시민 부대가 아가토클레스에 맞서 백튀니스 전투에서 궤멸당했다.\\\\n\\\\n기원전 310년의 전멸 이후, “신성대”는 역사 기록에서 사라졌다. 카르타고 시민 부대는 이후 전쟁 기간의 사료에서 등장하는데, 그들의 숫자는 위기 때문에 징집병으로 사용가능한 모든 시민들을 포함시켜 눈에 띄게 증가되었다. 규모가 커진 시민군들은 제1차 포에니 전쟁 동안에 일어난 바그라다스 전투, 용병 전쟁, 제3차 포에니 전쟁에서 나타났지만, “신성대”는 이 전쟁 시기에 현재까지 남은 자료들에서도 언급되지 않았다.', '《파르므의 승원》(La Chartreuse de Parme)은 1839년 출판된 스탕달의 장편소설이다. \\\\n\\\\n16세기 이탈리아 고서(古書)를 골자로 하여 겨우 2개월 만에 써버린 작자 원숙기의 작품이다. 발자크가 격찬하여 스탕달이 생전에 인정을 받았던 유일한 작품으로 유명하다.\\\\n\\\\n나폴레옹을 동경한 대귀족의 아들 파브리스는 워털루 전투에 참가한 때문에 음모의 와중에 휩쓸린다. 그를 돕는 정열적인 상세베리나 공작 부인과, 기지에 찬 그의 여인 모스카 백작, 파브리스를 사랑하는 수줍고 상냥한 크레리아 등 네 사람에게 던져진 전제정치의 어두운 그림자를 그렸다. 결투, 탈옥, 독살의 여러 사건이 전개된 뒤에 파브리스의 아들을 잃은 크레리아는 절망으로 죽고 파브리스는 수도원으로 들어간다.\\\\n\\\\n작가가 소설에 몇 번이나 테마로 한 나폴레옹 몰락 이후의 사회에 있어서 인간의 생존방식을 여기에서도 문제삼고 있다. 그러나 모두가 희가극(喜歌劇)류의 풍자와 애수를 띠고 진행되어 <적과 흑>처럼 우울하지는 않다. 작자는 파브리스의 천진난만 속에 그렇게 되기를 바래 왔던 자신의 모습을 몽상하고 크레리아에게 이상적 애인의 영상을 그려보려고 했던 것이다. ‘행복의 추구’가 이 작품의 중심 테마라 하겠으며 다시 읽고 또 읽음으로 하여 더욱 흥미가 일어나는 명작이다. 더욱이 워털루 전투 묘사는 톨스토이의 <전쟁과 평화>에도 영향을 끼쳤다고 한다.', '\"역번역\"이란 번역된 문장을 다시 원문의 언어로 참고나 주석 없이 되돌리도록 하는 행위를 말한다. 번역본이 공지된 허가를 얻은 상태에서 임상 목적이나 치료의 목적으로 사용됐을 시 유럽연합의 윤리위원회나 기관생명윤리위원회의 감독 하에 역번역이 이뤄진다. \\\\n\\\\n기계번역의 경우 역번역의 영어 용어는 \"round-trip translation\"(왕복)로 불리기도 한다.\\\\n\\\\n역번역과 원문을 비교하는 행위는 보통 원문 번역과의 질적 대조를 꾀하기 위함이다. 적절한 방법이기는 하지만 꼭 완벽한 결과를 제시하는 방법으로 볼 수는 없는 오점이 있다. \\\\n\\\\n고문서로 발견된 유물이 원어로는 존재하지 않고 번역된 언어로만 존재할 경우에 고고학자들이 원어로 바꾸어 원문을 되살리려는 노력을 하기도 한다. 유사하게 역사학자들이 다른 언어로부터 번역된 문서로 의심되는 유물을 발견했을 시 역추적을 번역으로 이룸으로써 근거를 찾아낸다. 보통 특정 관용구나 언어, 미세한 문법적 구조로 발견할 수 있어 이런 특질을 바탕으로 원어로부터 파생된 번역본인지 가늠하기도 한다.\\\\n\\\\n예를 들어 틸 오일렌슈피겔에 대한 고지독일어로 표현된 이야기들 중에서는 저지독어로만 표현 가능한 익살을 표현하는 경우가 있다. 이런 경우에는 이야기들이 전부 내지는 적어도 상당부분 원래 저지독어로 쓰여졌고 고지독어로 번역돼 좀 더 의역의 표현법이 과장됐음을 나타낸다.\\\\n\\\\n유사하게 아람어 원어론의 지지자들의 관점에서도 예를 찾을 수 있다. 그들은 신약성서나 원문이 원래 아람어로 쓰여졌다고 보는데 그 근거를 각기 존재하는 다른 고대 그리스어 신약성서본과 비교했을 시 아람어로 역번역한 번역본이 훨씬 매끄럽다는 데 있다. 그리스어에서 표현되지 않거나 이해할 수 없는 익살이나 문법적 특질이 아람어에서는 번역 가능하기 때문이다.', '봉성군이 유배를 떠나고 1년이 지난 1547년(명종 2년) 음력 9월 18일, 부제학 정언각이 한강 이남의 양재역 에서 한 장의 익명서를 발견하고 이를 명종에게 고하였다. 당시 익명서에는 \"여주가 위에서 정권을 잡고 간신 이기 등이 아래에서 권세를 농간하고 있으니 나라가 장차 망할 것을 서서 기다릴 수 있게 되었다. 어찌 한심하지 않은가. 중추월 그믐날.\" 이라는 내용이 붉은 글씨로 쓰여 있었다. 이른바 양재역 벽서 사건이며, 을사사화의 여파로 일어난 사화로 정미사화라고 칭하기도 한다 . 당시 이 사건은 문정왕후와 윤원형 일파가 사림 세력을 제거하기 위해 조작한 사건이었다 .\\\\n\\\\n이러한 일이 일어난 것에 대해 윤원형 일파는 애초에 윤임 등의 역모를 다스릴 때에 그 처벌을 가벼이 했기 때문이라고 간하고, 이어 윤임 일파는 물론이고 봉성군에 대해서도 모조리 죽일 것을 간하였다. 이때 명종은 계림군에 대해서만 사사를 명하였는데, 당시 이 사건을 《실록》에 기록한 사관은 이기 일파가 윤임 일파를 역적으로 몰아버리고, 이를 증명하기 위해 봉성군마저 죽일 것을 간한 것은 너무 심한 처사라며 비판하였다 . 그러나 이후에도 봉성군을 죽이라는 상소는 계속되었으나, 명종은 전혀 윤허하지 않았다 .\\\\n\\\\n한편 당시 홍문관에 재직 중이던 이황도 봉성군을 죽이라는 차자를 올렸다고 그 제자가 증언하였다 .', '장면은 값비싼 영한 사전과 영어 사전을 구입하지 못하는 학생들을 위해 영한 사전의 필사본을 인쇄하여 천주교회에 비치하여, 평양부와 경성에 보급하였다. 영어사전과 영한사전을 구하고 싶어도 값이 비싸서 구하기 어려웠던 고학생들은 성당에 찾아와 그가 인쇄한 영한사전과 영어사전을 가져갔다.\\\\n\\\\n1936년 11월 동성상업학교 박준호(朴準鎬) 교장이 별세하자 동성상고 서무주임으로 있던 장면은 11월 19일 천주교재단의 추천으로 동성상업학교 교장에 천거되어 취임하였다 동성상업학교 교장에 취임하자 그는 조선총독부가 감시를 위해 파견한 일본인 교사 사이고를 축출했다. 1937년 4월 1일 경성 혜화유치원 원장이 되었고 38년 학사 시찰차 출국, 3주간 일본을 방문하고 돌아왔으 1938년 친일단체인 국민정신총동원조선연맹 간사에 선출되었다\\\\n\\\\n1938년 10월 20일 국민정신총동원조선연맹 산하의 비상 시 국민생활개선위원회 제1부 위원 44명 중 1인으로 선임되어 명동천주교회를 국민정신총동원조선연맹에 가입시켰고 같은 해 5월 14일에는 국민정신총동원 천주교 경성교구연맹의 간사로 참여하였다. 그러나 이때의 칼럼 기고 등은 그가 적극적인 친일행위를 했다기 보다는 천주교 교단을 살리기 위한 소극적인 부일에 불과했다는 반론도 있다. 당시의 이런 활동은 그가 제7대 국무총리로 임명될 무렵 과거전력논란의 원인이 되기도 하였다.', '최초고용계약의 지지자들은 이 노동법이, 프랑스내 실업난, 특히 가난한 젊은이들의 실업난을 해소해줄 것이라 믿었다.\\\\n이들은 최초고용계약이 해고를 더 쉽게 할 수 있도록 하여, 고용인들의 신규 인력 채용에 대한 부담을 감소시키고, 프랑스의 심각한 청년실업난 해소를 감소시킬 수 있다고 보았다. 프랑스의 강력한 고용 보장정책을 해고를 쉽게 하는 것으로 완화시키면, 신규인력 채용에 대해 부담을 덜 갖게 되어, 구인자들이 청년 구직자들을 고용할 것이라고 본 것이다.\\\\n한편, 대부분의 좌파 정치단체 및 Union for French Democracy와 같은 일부 우파 단체들 그리고 프랑스 국민의 64%가 이 법을 반대하였다. 반대자들은 이 법을 이른바 \"클리넥스 계약\"이라면서 비판적으로 부른다. 이는 고용인들이 젊은이들을 화장지처럼 필요할때는 쓰다가 필요없어지면 버릴 수 있다고 인식하게 만들 것이라는 논리이다. 최초고용계약은 도미니크 드빌팽 프랑스 총리가 제안하였다. 자크 시라크 프랑스 대통령은 3월 31일 저녁 최초고용계약을 인준하였으나, 이와 동시에 2년간의 해고가능기간을 1년으로 줄이는 것과, 해고의 이유를 고용주가 입증해야 하는 요지를 가지는 새로운 법을 도입할 것을 정부에 요청하였다.', \"19세기 말부터 러시아의 진보적 귀족과 러시아 농촌 내 농민에게서 자생적으로 발생한 브 나로드에서 파생된 나로드니키주의(Народничество) ― 소위 당시 인민주의라고도 불린 ― 에 대하여 레닌은 농업 발전의 모든 양상을 거부한 극단적인 정체적 사고라고 비판하였다. 당시 러시아 인민주의자들은 자본주의적 농업 소유 구조는 농업 소유 구조에서 완전한 악(惡)이라고 보았다. 이들은 자본주의적 농업 소유 구조는 인간의 선의에서 벗어난 반인류적 구조인 것이며, 과거의 원시적 농업 형태가 선(善)에 해당하는 공산주의적 공동체의 전형이라고 주장했다. 블라디미르 레닌은 당시 유럽국가의 산업 발전과 농업 구조의 변혁을 실증적으로 검토하였고, 마르크스주의의 지대 이론에 따라 자본주의적 농업 구조는 이전 봉건적 농업 구조에 대해서 발전된 양상이라고 보았다. 자본주의 특유의 소규모 자영농 위주의 농업 생산 구조는 산업의 발전을 촉진시킨 결과물로 나온 것이며, 기본적으로 이 과정에서 지주의 권한을 대폭 약화시켰다. 즉, 이전의 봉건적 농업 구조에 비해 '농지'(農地)이라는 생산수단에 대해서 인민이 더 쉽게 접근할 수 있게 된다고 본 것이다. 이러한 입장에 기반하여 블라디미르 레닌은 러시아 인민주의자들이 경제 문제에 도덕주의라는 허울을 들씌웠다고 비판하였다. 즉, 그들의 주장은 고대사회부터 현재에 이르기까지 진행된 모든 소유 구조의 발전 과정을 염두에 두지 않은 주장이란 것이다. 블라디미르 레닌에게 있어서 이 인민주의 운동은 일종의 공상적 사회주의와 비슷한 것이었다.\", '9월 15일, 마리아나 제도의 알라마간 섬에서는 거의 10 km이내에 태풍 초이완의 눈이 통과했고 이 태풍은 230 km/h의 바람을 내면서 통과하였다. 태풍 초이완이 통과하기 전에 가장 최근에 마리아나 제도를 통과한 태풍은 2004년의 태풍 차바였다. 태풍 차바는 사피어-심프슨 허리케인 등급 제5등급으로 차바로 인해 매우 심한 피해와 광범위한 지역에 홍수가 났으나 태풍 초이완은 상대적으로 매우 적은 비가 내리게하였다. 이 태풍의 가장 큰 피해는 사이판에서 났는데 많은 나무가 부러지면서 거리에 나뒹굴었다. 전선이 끊겼고 하수구 파이프가 손상되었으나 태풍 초이완이 지난 후 고치기 시작했다. 가라판에서는 매우 적은 피해를 내어서 대략 1주일에 모든 복구가 가능할 것으로 예측했다. 알라마간 섬에서는 엄청나게 강력한 태풍이 지나갔음에도 불구하고 섬에 살고 있는 16명의 거주자가 안전했다. 미국 해군은 알라마간 섬은 매우 피해가 심해 전체 구조물 중 하나를 제외한 모든 구조물이 손상되었고 실험실과 연구소가 파괴되었고 나무도 쓰러졌다고 보고했다. 이 섬이 피해가 심했기 때문에 모든 거주자들의 대피가 시급하다고 판단하여 4일 된 아기를 포함한 6명의 가족들이 최초로 사이판에 대피하였고 4일 된 아기는 사이판의 병원으로 보내져 치료를 받았다.', '에도 시대 후기에 개국하여 왕정복고에 의해 성립된 메이지 정부는 사민평등 정책 하에 다이묘, 무사 계급을 폐지하고 화족(華族), 사족(士族)을 창설한다. 녹봉 처분에 의해 봉록 (가록) 제도는 철폐되고 폐도령의 시행 등 신분적 특권도 폐지되었다. 또한 메이지 정부가 시행하는 문명개화, 식산흥업 정책에 의한 서양 기술, 문화의 수입, 조선 출병을 둘러싼 정한론을 둘러싸고 정부가 분규를 겪으며, 메이지 6년 정변으로 사이고 다카모리, 에토 신페이, 이타가키 다이스케 등이 하야하면서 사족 층에 영향을 주어 메이지 정부에 반대하는 사족을 ‘불평사족’이라고 불렀다.\\\\n\\\\n1874년 에토 신페이가 고향 사가현에서 옹립되어 반란(사가의 난)을 일으키고, 1876년에는 구마모토현에서 ‘신푸렌의 난’(神風連の乱)에 호응해 후쿠오카현 아키즈키 번의 번사 미야자키 샤노스케를 중심으로 ‘아키즈키의 난’(秋月の乱), 10월에는 야마구치현에서 마에하라 잇세이 등에 의한 ‘하기의 난’(萩の乱) 등 반란이 이어지며 각각 진압되었다.\\\\n\\\\n1877년에는 구 사쓰마 번의 사족이 중심이 되어 사이고 다카모리를 대장에 옹립하여 일본 국내에서는 최대 규모의 내전이 되는 ‘세이난 전쟁’이 발발한다. 사이고 다카모리에 호응하는 형태로 후쿠오카에서도 타케베 고시로오 등 구 후쿠오카 번 사족에 의해 ‘후쿠오카의 변’이 일어났다. 정부는 반란군의 2배 이상의 병력을 투입해 진압했지만, 병력 수, 장비, 병참 등 정부군은 모든 면에서 사이고 군보다 유리한 조건을 가지고 있었음에도 불구하고 동일한 전사자 수, 전상자가 발생하는 등 정부의 군사적 약점을 드러내는 결과가 되었다. 이 전투는 일본의 뒤이은 부국강병 정책의 초석이 되었다. 또한 이른바 사쓰마 번 출신인 삿초 도이(薩長土肥) 등에 의한 번의 파벌을 낳기도 했다.\\\\n\\\\n세이난 전쟁 이후 불평 사족의 반대 운동은 국회 개설과 헌법 제정을 요구하는 자유 민권 운동으로 이행된다.', '이오의 산\\\\n이오의 산 목록\\\\n 이오에는 100~150개의 산이 있다. 이들 산의 평균 높이는 6 킬로미터이며 가장 높은 사우스 보사울레 몬테스는 17.5±1.5 킬로미터에 이른다 이오의 산들은 크고(산의 평균 지름은 157 킬로미터이다.) 지질구조상으로 정형화된 윤곽이 특별히 없이 고립된 구조처럼 보이는데 이는 지구의 경우와 비슷하다 이처럼 엄청나게 큰 규모의 지형이 유지되려면 그 구성요소는 대부분이 황이 아닌 규산염 암석이어야 한다. \\\\n\\\\n이오의 독특한 겉모습을 만들어 준 광범위한 화산 활동에도 불구하고, 이오의 산 대부분은 화산활동으로 생긴 것이 아니라 지질 구조이다. 이오의 산 대다수는 암석권 아랫부분에 가해지는 압축응력으로 생겨난 것이며, 압력을 받은 이오의 지각판은 충상 단층 작용을 통해 솟아오르고 기울어진다. 산을 만드는 압축응력은 화산 물질이 계속하여 지각 아래로 침하하기 때문에 생긴다. 여기서 이오의 암석권에 압축(산을 만드는 힘)과 신장(파테라를 만드는 힘) 작용이 지배하는 거대한 영역이 있는 것으로 보인다. 그러나 지역적으로는 산과 파테라가 서로 닿아 있는 모습도 자주 관측되는데, 산이 생길 때 만들어진 단층 사이를 마그마가 비집고 표면으로 올라오는 것으로 추측된다\\\\n\\\\n이오의 산(일반적으로 평원 가운데 솟아 있는 구조)은 다양한 형태를 보인다. 고원 모양이 가장 흔하 이 구조는 거대하고 꼭대기가 평평하며 표면의 기복이 심하여 지구의 메사와 닮았다. 다른 산들은 기울어진 지각 덩어리처럼 보이는데, 이전에 평평했던 땅이 완만하게 기울어진 부분과, 예전에 땅 속에 있다가 압축응력으로 지표면으로 솟아올라 가파르게 경사진 부분으로 이루어져 있다. 이들 두 종류의 산 모두 하나 혹은 그 이상의 경계면을 따라 가파른 절벽이 형성되어 있는 경우가 많다. 화산 활동으로 생겨난 산은 몇 개 없어 손에 꼽을 정도이다. 이들은 작은 순상 화산과 닮았으며 중앙부의 칼데라 근처에서는 경사(6~7도)가 가파르나 가장자리를 따라서는 경사가 완만하다. 이 산들은 다른 평균적인 산들에 비해 작으며 높이는 1~2 킬로미터, 폭은 40~60 킬로미터이다. 경사가 훨씬 완만한 다른 순상 화산들은 라 파테라처럼 파테라 중앙부에서 용암류가 뿜어져 나오는 형태이다\\\\n\\\\n거의 모든 이오의 산이 어떤 열화(劣化) 단계에 있는 것으로 보인다. 큰 규모의 산사태 퇴적물이 이오 산 아랫부분에 흔하여 붕괴작용이 열화의 대표적인 형태임을 알 수 있다. 물결모양의 가장자리는 이오의 메사와 고원 지형에 자주 보이는데, 이는 이오의 지각으로부터 이산화 황이 뚫고 나와 산 가장자리를 따라 연약한 지대를 만들기 때문이다.', '공화국은 수 만년 동안 소규모의 군대를 보유하고 있었지만, 개혁이 일어난 후 일정 규모 이상의 군대를 양성하지는 않았다. \\\\n\\\\n하지만 무역 연합과 기업들은 이와 같은 점을 악용하여 개인용 군대를 키우기 시작, 결국 나부를 점령하고 공화국에게 정면으로 도전하게 된다. 이와 같은 상황은 공화국에게 대규모 군대를 양성해야 할 필요를 느끼게 했으며, 공화국의 지도자들은 군대를 만들 방법을 강구하기 시작한다. \\\\n\\\\n그러던 중, 10년 전 한 제다이 마스터가 행성 카미노에서 초대형 클론 군대를 만들 것을 지시했다는 사실이 알려진다. 분리주의 연합이 공화국과 평화적으로 협상할 의도가 없다는 것이 확실해지자, 공화국 의회는 이 클론 군대를 곧바로 투입할 것을 지시했고 이 때부터 클론 전쟁이 일어나게 된다. \\\\n\\\\n공화국 육군은 수백만 명에 달하는 클론 병사들을 보유하고 있었으며, 이들은 최고의 무기와 갑옷을 갖추고 집중 훈련을 받은 최고의 육군 병력이었다. 최신 기술을 접목시킨 AT-TE 워커, AT-RT 워커, 클론 저거너트, UT-AT 및 LAAT 건쉽들이 공화국 군대를 위해 제작되었다. 행성의 환경에 특수하게 맞춘 사단들이 신속하게 만들어졌으며 각 부대는 특정한 역할을 수행했다. 공화국 해군은 수백, 수천의 다양한 순양함, 구축함, 항공 모함 및 호위 순양함으로 구성되었다. 공화국 군대의 병사들은 거의 모두가 클론이었으며, 공화국 군 장교는 장교 아카데미에서 선발된 클론 혹은 제다이였다. 공화국 군대의 최고 지휘부는 숙련된 지도자들, 즉 경험 많은 장교로 구성되어 있었으며, 거의 모든 작전들을 성공시켰다. 공화국 군대는 양과 질 이 모든 분야에서 거의 완벽을 자랑했다.']\n",
      "['수감 생활의 고통에 비하면 고문의 고통은 아무것도 아니라고 기술한 인물은?', '유성 생식을 하지 않는 생물의 종류는?', '베토벤은 무엇에 대한 근심으로 유서를 작성하였나요?', '크렘린 궁과 함께 러시아를 대표하는 겨울 궁전이 위치해 있는 지역은 어디인가?', '서울 지역 대학교 총학생회에 도움을 준 회사는?', '민간인을 상대로 무차별 공격을 벌인 군대는?', '질량이 비슷한 2개의 별이 쌍성계를 이루고 있을 때, 이 쌍성계의 질량 중심은 어디인가?', '도쿠가와 이에야스는 어떤 전쟁 때문에 소마 가문을 서군으로 간주했나요?', '김세진의 죽음이 영향을 준 인물은?', '카르타고 신성대가 활동했던 시대는 언제인가?', '작가가 자신의 이상적인 자아상을 투영시킨 인물은?', '고고학자들은 어떤 상황일 때 원어를 활용해 원문을 복원하려고 하는가?', '사림 세력 제거를 모의했으며 이황과 뜻이 일치했던 세력은?', '동성상업학교 교장으로 직무를 수행하기 전 장면의 직장은?', '최초고용계약을 통해 무엇이 쉽게 가능해질 수 있는가?', '블라디미르 레닌이 자본주의 방식의 농업 구조가 과거 봉건적 농업 구조에서 발전된 모습이라는 것을 참고한 개념은?', '사이판의 전선과 하수구 파이프는 언제 수리하기 시작했는가?', '메이지 정부의 개혁에 이의를 제기하는 가문을 뭐라고 지칭했는가?', '이오에 있는 산들 중 가장 높은 산은 무엇인가?', '최고 지휘부 구성원으로 선출된 사람들은 어디 출신인가?']\n"
     ]
    }
   ],
   "source": [
    "sample_idx = np.random.choice(range(len(train_dataset)), 20)\n",
    "training_dataset = train_dataset[sample_idx]\n",
    "print(training_dataset['context'])\n",
    "print(training_dataset['question'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c653dfd1-8567-4c9a-b7fb-f4a61d062df2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
