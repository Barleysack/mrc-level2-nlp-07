

































































































































































































































































































































 52%|████████████████████████████████████████████████████████████▋                                                        | 14999/28940 [11:00<5:06:39,  1.32s/it]











































































































































































































































































































































 54%|██████████████████████████████████████████████████████████████▋                                                      | 15499/28940 [22:10<5:00:55,  1.34s/it]












































































































































































































































































































































 55%|████████████████████████████████████████████████████████████████▋                                                    | 16000/28940 [33:22<5:08:56,  1.43s/it]


















 55%|████████████████████████████████████████████████████████████████▊                                                    | 16028/28940 [34:08<4:50:09,  1.35s/it]Traceback (most recent call last):
  File "train.py", line 395, in <module>
    main()
  File "train.py", line 121, in main
    run_mrc(data_args, training_args, model_args, datasets, tokenizer, model)
  File "train.py", line 360, in run_mrc
    train_result = trainer.train(resume_from_checkpoint=checkpoint)
  File "/opt/conda/lib/python3.8/site-packages/transformers/trainer.py", line 1162, in train
    self.optimizer.step()
  File "/opt/conda/lib/python3.8/site-packages/torch/optim/lr_scheduler.py", line 67, in wrapper
    return wrapped(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/transformers/optimization.py", line 345, in step
    exp_avg.mul_(beta1).add_(grad, alpha=1.0 - beta1)
KeyboardInterrupt