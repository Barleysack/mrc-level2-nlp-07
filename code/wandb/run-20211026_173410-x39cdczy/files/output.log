

































































































































































































  2%|██▊                                                                                                                          | 498/22220 [06:27<4:40:35,  1.29it/s]




































































































































































































  4%|█████▌                                                                                                                       | 999/22220 [13:27<4:32:07,  1.30it/s]











































































































  6%|███████                                                                                                                     | 1271/22220 [17:28<4:29:52,  1.29it/s]Traceback (most recent call last):
  File "train.py", line 379, in <module>
  File "train.py", line 108, in main
    run_mrc(data_args, training_args, model_args, datasets, tokenizer, model)
  File "train.py", line 343, in run_mrc
    trainer.save_model()  # Saves the tokenizer too for easy upload
  File "/opt/conda/lib/python3.8/site-packages/transformers/trainer.py", line 1120, in train
    tr_loss += self.training_step(model, inputs)
  File "/opt/conda/lib/python3.8/site-packages/transformers/trainer.py", line 1542, in training_step
    loss.backward()
  File "/opt/conda/lib/python3.8/site-packages/torch/tensor.py", line 221, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/opt/conda/lib/python3.8/site-packages/torch/autograd/__init__.py", line 130, in backward
    Variable._execution_engine.run_backward(
KeyboardInterrupt